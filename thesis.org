#+TODO: TODO UPNEXT DOING REVIEW DONE
#+OPTIONS: \n:t H:5 toc:nil title:nil date:nil
#+LATEX_CLASS: book 

* Inbox
** DONE thesis declaration
CLOSED: [2019-01-28 Mon 21:11]
added on [2018-12-26 Wed 13:42]
** https://mcss.mosra.cz/doxygen/
** tasks
*** Code
**** components
***** generate reports
***** use a separate class in the extern functions
***** move the sanitizercoverage flag to coveragereported
don't forget to update docs
**** fuzzing
***** add a few simple fuzzmutate functions
*** Thesis
** TODO in functionPointerMap talk about all the cool features I'm using
 added on [2019-04-13 szo 13:23]
* meetings
** <2018-11-12 Tue 13:39>
*** summary 
After going through
** <2018-11-26 Mon 13:40>
*** summary
First draft
** <2018-12-13 Thu 13:40>
*** summary
created the declaration of thesis
*** decisions
**** will use clang code coverage instead of libfuzz
My arguments:
***** don't need randomized input
is that for combinations, there is a finite amount of sets we could test, which will be a subset of a much larger input set that libfuzz might provide us with (ie useless filtering of garbage)
***** better coverage info
libfuzz will filter out code coverage information that is irrelevant for APIs but might be crucial in terms of function combinations 
****** TODO examples
***** extracting information
More control over combination hierarchy, no need to go through trouble of extracting it manually from libfuzz corpus (don't even know if it's possible in full form)
** <2019-02-26 Tue 15:08> 
*** report
**** tried llvm-cov and then found sanitizerCoverage
exactly what we needed and also what libfuzzer uses
**** fixed functionPointerMap
was forgetting to pass the class instance, then forgetting to pass by reference
**** created CombinationGenerator
doesn't store all combinations, insted just indexes
would be suitable for multithreading too
*** discussion topics
**** current issues
***** storing function arguments
since functions are cast to void, I can't use decltype anywhere. everything has to be excplicitly specified. Right now I'm just ignoring the return value (technically do we need it?)
should I use boost::any?
std::any in c++17 or std::variant (better) also http://gsd.web.elte.hu/gyak/cpp17util.pdf
***** coverage_pc does not work for template files
pc_guards are inserted when creating the object file, otherwise it inserts the guards aaaall over the place. 
**** design decisions
***** what information to extract during processing
right now it's recorded by function call (simple bool started) maybe I should record guards by each function in the sequence and see how calling other functions affects its guards 
***** [[function interaction][how to analyze coverage]
**** what's next
***** start implementing [[design decisions]]
***** start learning clang AST
***** try to use threads
for 5 most primitive functions and 8 combinations, it takes 5 seconds already 
**** misc tasks
***** start documentation
***** makefile
***** gdb
***** more tests
** <2019-03-15> Presentation (actually date is inaccurate)
*** process description
**** store function pointers in a map
**** collect coverage
***** initially thought to use libfuzzer
[[some differences from fuzzing]]
***** explored other paths
****** llvm-cov
summarizes the intire run, so if I call three different combinations of functions they results will be mixed in together. But it has some nice visualization data and maybe that could be used to display the results
looked into libfuzzer source code to find out what they where using to collect the coverage, since they were doing multiple "isolated" runs to analyze
****** sanitizercoverage
******* how it works
guards are inserted at function entrance points, if/else block starts, etc. You can implement the functions that get called when the guard is initialized and then when it's called
******* how I use it
there is one main function that has the map with all the functions
**** analyze coverage
***** base assumptions
****** order of calls does not matter
****** 
*** next steps
**** 
*** notes from meeting
**** TODO ...
***** having an additional argument
make some measurements
***** take std::vector
and ignore some of the functions, for example insert, erase etc, and just use push_back, pop_back;
***** maybe deck too
compare what was the behavior of the stuff
***** user manual, developer manual, test cases
*** TODO ...
**** grammar induction
exhaustive search on relatively small input to infer the grammar. 
**** generational algorithm
the way it overcomes the gaps 
mutations like appending to random sequences together 
**** contact libfuzzer developers
*** some differences from fuzzing
**** coverage info
libfuzzer is created with different intent in mind and extracting the coverage information which is already filtered according to the library's priority might not be what we want
**** possible input space
much larger in fuzzing, more limited (and deterministic) here
**** path exploration
since it's more feasible to keep exploring different paths (for example calling the same function 17th time will unlock a new pc block) 
**** handling exceptions
fuzzer will hault on first exception it finds, because the design philosophy is that the consumer is an API. In case of libraries, exceptions might be expected so here each function (or combination?) call will be wrapped in a try catch so all the different call sequences that result in various exceptions
** <2019-03-29> 
*** 
* other
** Project outline
*** Motivation
start with linear number of test cases but at some point it explodes. Hard to determine which test cases are meaningful. 
*** About fuzzing
*** What can't be covered with fuzzing
**** Does not consider the interaction of different functions
If you write a TDD application, there is a well defined interface of functions.
**** APIs should be tolerable
(reference cppcon 17 video)
Any kind of crash/abort/assert failure/timeout is considered a bug in an API, whereas for libraries it could be expected behavior that should be covered in tests
*** ..
**** why we're considering every possible input
there might be new code coverage anywhere, and since it is a finite set...
** Process description
*** Analyze the library
**** TODO what information can be inferred automatically?
What will be the manual tasks that the programmer will need to do and specify for the library to work
***** Type information
should be able to do with clang
*** Generate 

*** Run coverage tests
**** TODO how will the function inputs be handled?
- my idea is to test each of the functions using libfuzz (would need to somehow get the output still)
- it might be best for the programmer to provide 
*** Analyze and communicate the results
**** TODO give the smallest possible subset of function combinations
**** TODO extra information
- What else does the interaction of functions tell us?
- Can we predict possible problems with the function based on code coverage
* Research / Learning
** DOING c++ tutorials
general knowledge of language since I don't have a lot of experience currently
*** std::forward http://cpptruths.blogspot.com/2012/06/perfect-forwarding-of-parameter-groups.html
** clang
*** DOING understand code coverage library
*** DOING get familiar with libfuzz source code
understand how libfuzz works since a lot of mechanisms are similar

*** TODO AST
will be needed for extracting type information
** c++ reference
*** typeinfo
**** typeid
Used where the dynamic type of a polymorphic object must be known and for static type identification. The typeid expression is an lvalue expression which refers to an object with static storage duration, of the polymorphic type const std::type_info or of some type derived from it.
result refers to [[type_info]]
**** type_info
The class type_info holds implementation-specific information about a type, including the name of the type and means to compare two types for equality or collating order. This is the class returned by the [[typeid]] operator.
**** type_index 
The type_index class is a wrapper class around a std::type_info object, that can be used as index in associative and unordered associative containers. The relationship with type_info object is maintained through a pointer
** related work
*** klee 
http://klee.github.io
papers
**** KLEE: Unassisted and Automatic Generation of High-CoverageTests for Complex Systems Programs
http://www.doc.ic.ac.uk/~cristic/papers/klee-osdi-08.pdf
**** Abstract
We  present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage — on average over 90 %per tool (median: over 94%) — and significantly beat the coverage of the developers’ own hand-written testsuite. When we did the same for 75 equivalent tools inthe BUSYBOX embedded system suite, results were evenbetter, including 100% coverage on 31 of them.
We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.
**** difference
operates on bytecode instead of c++, which means the results cannot be easily implemented in ci or sth
*** KLOVER: A Symbolic Execution and AutomaticTest Generation Tool for C++ Programs
http://www.cs.utah.edu/~ligd/publications/KLOVER-CAV11.pdf
**** abstract
We present the first symbolic execution and automatic testgeneration tool for C++ programs. First we describe our effortin extend-ing an existing symbolic execution tool for C programs to handleC++programs. We then show how we made this tool generic, efficientandusable to handle real-life industrial applications. Novelfeatures includeextended symbolic virtual machine, library optimization for Cand C++,object-level execution and reasoning, interfacing with specific type of ef-ficient solvers, and semi-automatic unit and component testing. This toolis being used to assist the validation and testing of industrial softwareas well as publicly available programs written using the C++ language
**** notes
As shown in Fig. 1, the tool’s flow is similar to KLEE’s. A C++ program is compiled into LLVM bytecode, which is interpreted by KLOVER for symbolic execution
** commands and stuff
*** llvm-cov
https://clang.llvm.org/docs/SourceBasedCodeCoverage.html

#+BEGIN-EXAMPLE
clang++ -fprofile-instr-generate -fcoverage-mapping stack.cpp -o stack
LLVM_PROFILE_FILE="stack.profraw" ./stack
llvm-profdata merge -sparse stack.profraw -o stack.profdata
llvm-cov show ./stack -instr-profile=stack.profdata
llvm-cov report ./stack -instr-profile=stack.profdata
llvm-cov export ./stack -instr-profile=stack.profdata > export.json
#+END-EXAMPLE
**** flags
***** sparse
The -sparse flag is optional but can result in dramatically smaller indexed profiles. This option should not be used if the indexed profile will be reused for PGO.
* resources
** fuzzing
https://resources.infosecinstitute.com/fuzzing-mutation-vs-generation/#gref
https://www.wikiwand.com/en/Fuzzing
https://www.securityevaluators.com/wp-content/uploads/2018/04/analysisfuzzing.pdf
* content
:PROPERTIES:
:EXPORT_TITLE: Test case generation based on fuzzing for C++
:END:

#+LATEX_HEADER: \date{2019}

#+LATEX_HEADER: \degree{Computer Science BSc}

#+LATEX_HEADER: \supervisor{Zoltan Porkolab}
#+LATEX_HEADER: \affiliation{Associate Professor}


#+LATEX_HEADER: \university{Eötvös Loránd Tudományegyetem}
#+LATEX_HEADER: \faculty{Faculty of Informatics}
#+LATEX_HEADER: \department{Department of Programming Languages}
# TODO and compilers 
#+LATEX_HEADER: \city{Budapest}
#+LATEX_HEADER: \logo{elte_cimer_szines}
#+LATEX_HEADER: \documentlang{english}
#+BEGIN_EXPORT latex
\begin{document}
\begin{titlepage}
\end{titlepage}
#+END_EXPORT

\vspace*{\fill}
Test based development is a favorable development method for modern software. We create all the necessary test cases to test the software under development and then we implement the functionality. This is a widely accepted method for library development, when the test cases try to cover all meaningful combinations of API calls. However, in real software systems, the possible combinations can grow exponentially. It is very hard to determine the minimun necessary set of meaningful API call sequences. In this thesis we try to apply fuzzy testing methods for automatically generate API call sequences for testing C++ libraries. We will use the LLVM toolset to exploit the existing code coverage and test input mutation methods. However, our target is not to gereate a random input sequence but a meaningful sequence of API calls. It is also in our plans to analyse the result to create a minimal classification set.

\vspace*{\fill}
\cleardoublepage
#+TOC: headlines 0

** inbox                                                          :noexport:
*** fuzzing
Generation based fuzzing
This step could be extended with g
** Looking for home :P                                            :noexport:
*** software verification tools
**** testing
# what to write here
***** aims
****** define expected outcomes of ...
- generate unit test cases that achieve the  most code coverage with least function calls
# code coverage
***** drawbacks
****** relies on the developer
****** does not anticipate bugs that are not trivial
****** 
to adress these, other methods are more and more frequently used
**** static analysis
***** usual code checking tools
- good for finding bugs, but does not touch code coverage
# have only short overview and  
***** symbolic execution
- works on bitcode / bytecode
- resource heavy
  - ? cannot substitute unit tests
  - ? not practical in a lot of cases where unit tests would suffice
- sometimes not realistic because of path explosion
**** dynamic analysis
***** fuzzing (with the example of llvm's libfuzzer)
ease of implementing 
******* aims

******* conditions assumed:
*** Explored Implementations
**** libfuzzer
***** Implementing
# Q should I provide sample code that I tried?
with libfuzzer, the user defines the callback that consumes data and is executed on each iteration.
***** 1. create a map of function pointers
****** talks about functionPointerMap class
In order to be able to dynamically call functions, I created a template class that is able to store member function pointers in a map and call them using keys. Storing functions with different types of return value and argument types is made possible by casting it to a void functiontype and saving it paired with the typeid. When calling the function using a key, user would specify the return type and pass any arguments needed for the call, which are then forwarded. Initially, I was discarding the return value and
 ommiting functions that needed arguments.
******* handling arguments
will be discussed later. Had short tries and decided to not include in this scope
# Q how should this be written?
******** std::variant
******** std::apply
***** 2. handling the LLVMFUZZINPUT content
****** how to map the data to map keys
One way would be to parse it for exact sequence of function names. Instead, I decided to extract chars and match it with digits 
***** 3. callback content 
******* validate input data'
We could try parsing the data for numbers and see if they satisfy the conditions ....  
******* create the instance
******* call all the functions
***** issues with the approach
****** challenges that arise in libraries but not in interfaces
******* handling exceptions
fuzzer will hault on first exception it finds, because the design philosophy is that the consumer is an API. In case of libraries, exceptions might be expected so here each function (or combination?) call will be wrapped in a try catch so all the different call sequences that result in various exceptions
******* mutations and path exploration
Library fuzzing might need different mutation techniques. For starters, function call is a sequence, and there are ways to create interesting inputs by being aware of it.

is that for combinations, there is a finite amount of sets we could test, which will be a subset of a much larger input set that libfuzz might provide us with (ie useless filtering of garbage)

For example, since it's more feasible to keep exploring different paths (for example calling the same function 17th time will unlock a new pc block). This is discussed in more detail later in . 
****** features of libfuzz unnecessary for our case
Even though libfuzzer will converge to the valid sequence calls very quickly, it will keep generating 'garbage' input which has no meaning in context of calling the function. 
******* possible input space
much larger in fuzzing, more limited (and deterministic) here
****** additional needs not accomplishable without changing libfuzzer implementation
******* coverage info
libfuzzer is created with different intent in mind and extracting the coverage information which is already filtered according to the library's priority might not be what we want. Would need to change implementation if we wanted to somehow define the way coverage is collected
**** llvm-cov
summarizes the intire run, so if I call three different combinations of functions they results will be mixed in together. But it has some nice visualization data and maybe that could be used to display the results
looked into libfuzzer source code to find out what they where using to collect the coverage, since they were doing multiple "isolated" runs to analyze
**** sancov
***** issues with the approach
no straightforward way exists to isolate coverage on different sequences. need multiple commands, and would 
**** sanitizercoverage
***** how it works
guards are inserted at function entrance points, if/else block starts, etc. You can implement the functions that get called when the guard is initialized and then when it's called
** Introduction
Most software heavily relies on unit tests as its primary source for logic and _fault tolerance_ verification. This approach has been largely considered as essential, but it has some inherent difficulties associated with it. Although testing single member functions independently is more often than not trivial, most of the time the user will call various combinations of them. It is impossible to write unit tests with all possible function call sequences since such space is effectively infinite. Therefore, the need arises for the developer to personally determine which function call sequences are most meaningful. 

Other than that, a lot of times the behavior of the function will depend on internal state of the instance, which is in itself reached after certain function calls.
*** Background on fuzzing
Fuzz testing reaches _amazing/astonishing_ results in exposing interface vulnerabilities in very short amount of time. 
|
_(one or two short paragraphs about fuzzing)_.
|
|
|
|
There are two ways for fuzzing, generation and mutation based. _(few words about those)_
|
|
|
*** _using fuzz testing for .._
Although fuzz testing has been mostly defined to be for exploiting the vulnerabilities of the program, _we decided_ to apply its coverage based philosophy to explore the possible member function call sequences and pinpoint ones which might be most interesting for the developer.
This also required to change the overall approach with which fuzzing is used. 
| 
|
_(talk about difference between classic interface fuzzing and our case)_
|
|
*** Program description
To acheive the intended results, I created a program that uses LLVM's _sanitizer coverage_ library and generation based fuzzing. The test case needs almost minimal setup which consists of the user specifying all the member functions it wants to use in testing, and passing a single function pointer for constructing an instance of the class. Modern c++ tools have aided greatly with this by giving the ability to store pointers to functions with different type signatures. There are still difficulties with regards to determining and passing the function arguments, which is in scope of a larger _research / project_. In order for this issue to not interfere with the initial program implementation, I allow users to additionally pass pointers to the functions that will in turn call the specific member function with desired arguments.

The _sanitizer coverage_ library is able to communicate its results using a single global object. _(more about this)_ 
*** Results
Although the original intention was to discover new test cases, there were some surprising outcomes that could not have been anticipated. For example, the program is very good in minimizing the total number of test cases. For the sample stack class, it discovered that _(move results here)_. This outcome would be crucial for reducing the size of test suites, which leads to reduced runtime and maintenance cost
** User Documentation
*** intended audience
this software is intended for c++ developers who would like to increase 
Therefore, at least basic knowledge of c++ is assumed, and the user will need to implement and pass pointers for several functions.
**** Requirements
test target should satisfy following:
***** The program is intended to test a single unit
Current version can not analyze any of the dependencies of the class.
***** You need to be able to be compiled separately
In order to analyze , the object file of the test target needs to be compiled with special flags separately of the rest of 
*** dependencies
*** installation instructions
run these commands from the directory where you want to install the project
#+ATTR_LATEX: :float nil
#+BEGIN_SRC sh
git clone  # download the contents in any way you want
cd <dir>
make test-main
make test # to make sure that everything works
#TODO create test-main which will compile catch, run unit tests, run integration test
#+END_SRC
After tests pass successfully, you can move on to next step and set up the  
*** setup and running
**** structure of the main file
# #+INCLUDE: src/main.cc example c++
# src c++ also works
# #+INCLUDE: "~/.emacs" :lines "5-10"   Include lines 5 to 10, 10 excluded
# #+INCLUDE: "~/.emacs" :lines "-10"    Include lines 1 to 10, 10 excluded
# #+INCLUDE: "~/.emacs" :lines "10-"    Include lines from 10 to EOF
*** output
**** results
**** memory leaks
any memory leaks will be discovered. For more info visit AddressSanitizer z
==32362==ERROR: LeakSanitizer: detected memory leaks
*** troubleshooting
There are few mistakes 
**** test if clang build works correctly
There might be problems with the addressSanitizer. To see if the program can run independently, use the make command, which will compile and run all the source files without the flag. The program will still work and call functions, but the coverage will not be reported. If this step is successful _describe how_ then please _check your compiler_
*** create a script that generates the main file
and also replaces the test target name in Makefile
** Developer Documentation
*** conventions
**** structure of the source folder
***** file extensions
this makes it easier to create a comprehensive but concise makefile which scans the source folder for .cpp files and 
.cc is used for main and 
***** src
***** test
discussed later in [[catch2]]
***** lib
**** using clang-format llvm 
_(short paragraph about style)_ you add `make format` to your commit hook, or alternatively use clang-format plugin for IDE of your choice. 
*** dependencies
**** sanitizer coverage
The program relies primarily on LLVM's built in coverage instrumentation to measure coverage of different function cal sequences. Basic understanding of how these functions work is necessary for development.
|
|
_(2-3 medium sized paragraphs about the internals of SanitizerCoverage)_
|
|
|
|
|
|
|
|
 
Sanitizer Coverage library offers numerous ways to observe the control flow of the program, including ones for. This could aid in refining the program for more complex applications.
# documentation
**** catch2
The project is thoroughly tested using the catch2 framework. 
|
_(short paragraph about why it was chosen)_
|
The hpp file is included with the project, in lib/ directory 
***** stBeps
#+BEGIN_EXAMPLE bash
make test-main
#+END_EXAMPLE 
This compiles the test-main.cpp which defines the main function of catch. Since it needs to be defined just once and used for any test case, it is more efficient to compile it to an object which is later included in tests.
#+BEGIN_EXAMPLE bash 
make test
#+END_EXAMPLE
runs the tests for all units in the project, excluding the combination tester.
|
|
_(I will create an integration test along with guards test here)_ 
|
|
**** documentation
Doxygen is used with javadoc style. All classes are thoroughly documented.
run doxygen Doxyfile to generate documentation in html and latex source. Latex source needs additional compiling which can be done by running the command `make` in the latex/ directory.
If you'd like to change doxygen settings, you can copy the Doxyfile and run doxygen my-Doxyfile.
 
